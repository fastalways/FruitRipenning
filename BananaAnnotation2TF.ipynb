{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def chang2annotation(src_image):\r\n",
    "  # grab the image dimensions\r\n",
    "  image = src_image.copy()\r\n",
    "  h = image.shape[0]\r\n",
    "  w = image.shape[1]\r\n",
    "  anno_banana = [255,255,255]\r\n",
    "  anno_bg = [0,0,0]\r\n",
    "  pixel_banana = [0,0,128]\r\n",
    "  pib = 0\r\n",
    "  # loop over the image, pixel by pixel\r\n",
    "  for y in range(0, h):\r\n",
    "    for x in range(0, w):\r\n",
    "        # convert (0,0,128) the pixel(Banana) to (1,1,1) = class 1 annotation for Banana\r\n",
    "        # no needed to do--- convert (0,0,0) the pixel(BG) to (0,0,0) = class 0 annotation for BG\r\n",
    "        cmp_output = image[y, x] == pixel_banana\r\n",
    "        if cmp_output.all() :\r\n",
    "          image[y, x] = anno_banana\r\n",
    "          pib = pib + 1\r\n",
    "        else :\r\n",
    "          image[y, x] = anno_bg  \r\n",
    "  print(f\"marked pixel {pib}\")\r\n",
    "  # return the thresholded image\r\n",
    "  return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import os\r\n",
    "# Read in folder anno_red\r\n",
    "path_anno_train = \"./banana2/anno_train_red\"\r\n",
    "fullNameList = []\r\n",
    "nameList = []\r\n",
    "for filename in os.listdir(path_anno_train):\r\n",
    "  if filename.endswith('png'):\r\n",
    "    fullNameList.append(path_anno_train+'/'+os.path.join(filename))\r\n",
    "    nameList.append(os.path.join(filename))\r\n",
    "print(nameList)\r\n",
    "print(fullNameList)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.png', '10.png', '11.png', '12.png', '13.png', '14.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n",
      "['./banana2/anno_train_red/1.png', './banana2/anno_train_red/10.png', './banana2/anno_train_red/11.png', './banana2/anno_train_red/12.png', './banana2/anno_train_red/13.png', './banana2/anno_train_red/14.png', './banana2/anno_train_red/2.png', './banana2/anno_train_red/3.png', './banana2/anno_train_red/4.png', './banana2/anno_train_red/5.png', './banana2/anno_train_red/6.png', './banana2/anno_train_red/7.png', './banana2/anno_train_red/8.png', './banana2/anno_train_red/9.png']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for i,value in enumerate(fullNameList):\r\n",
    "    print(value)\r\n",
    "    src_img = cv2.imread(value)\r\n",
    "    des_img = chang2annotation(src_img)\r\n",
    "    cv2.imwrite(\"./banana2/anno_train_bin/\"+nameList[i],des_img)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./banana2/anno_train_red/1.png\n",
      "marked pixel 625639\n",
      "./banana2/anno_train_red/10.png\n",
      "marked pixel 1821292\n",
      "./banana2/anno_train_red/11.png\n",
      "marked pixel 1722328\n",
      "./banana2/anno_train_red/12.png\n",
      "marked pixel 2136295\n",
      "./banana2/anno_train_red/13.png\n",
      "marked pixel 2078901\n",
      "./banana2/anno_train_red/14.png\n",
      "marked pixel 1677856\n",
      "./banana2/anno_train_red/2.png\n",
      "marked pixel 719434\n",
      "./banana2/anno_train_red/3.png\n",
      "marked pixel 699108\n",
      "./banana2/anno_train_red/4.png\n",
      "marked pixel 764545\n",
      "./banana2/anno_train_red/5.png\n",
      "marked pixel 745495\n",
      "./banana2/anno_train_red/6.png\n",
      "marked pixel 855855\n",
      "./banana2/anno_train_red/7.png\n",
      "marked pixel 776332\n",
      "./banana2/anno_train_red/8.png\n",
      "marked pixel 657648\n",
      "./banana2/anno_train_red/9.png\n",
      "marked pixel 807341\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resize anno"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import os\r\n",
    "# Read in folder anno_red\r\n",
    "path_anno_train = \"./banana2/anno_train_bin\"\r\n",
    "fullNameList = []\r\n",
    "nameList = []\r\n",
    "for filename in os.listdir(path_anno_train):\r\n",
    "  if filename.endswith('png'):\r\n",
    "    fullNameList.append(path_anno_train+'/'+os.path.join(filename))\r\n",
    "    nameList.append(os.path.join(filename))\r\n",
    "print(nameList)\r\n",
    "print(fullNameList)\r\n",
    "# Resize to 256x256\r\n",
    "for i,value in enumerate(fullNameList):\r\n",
    "    print(value)\r\n",
    "    src_img = cv2.imread(value)\r\n",
    "    des_img = cv2.resize(src_img, (256,256))\r\n",
    "    cv2.imwrite(\"./banana2/anno_train_resized/\"+nameList[i],des_img)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.png', '10.png', '11.png', '12.png', '13.png', '14.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n",
      "['./banana2/anno_train_bin/1.png', './banana2/anno_train_bin/10.png', './banana2/anno_train_bin/11.png', './banana2/anno_train_bin/12.png', './banana2/anno_train_bin/13.png', './banana2/anno_train_bin/14.png', './banana2/anno_train_bin/2.png', './banana2/anno_train_bin/3.png', './banana2/anno_train_bin/4.png', './banana2/anno_train_bin/5.png', './banana2/anno_train_bin/6.png', './banana2/anno_train_bin/7.png', './banana2/anno_train_bin/8.png', './banana2/anno_train_bin/9.png']\n",
      "./banana2/anno_train_bin/1.png\n",
      "./banana2/anno_train_bin/10.png\n",
      "./banana2/anno_train_bin/11.png\n",
      "./banana2/anno_train_bin/12.png\n",
      "./banana2/anno_train_bin/13.png\n",
      "./banana2/anno_train_bin/14.png\n",
      "./banana2/anno_train_bin/2.png\n",
      "./banana2/anno_train_bin/3.png\n",
      "./banana2/anno_train_bin/4.png\n",
      "./banana2/anno_train_bin/5.png\n",
      "./banana2/anno_train_bin/6.png\n",
      "./banana2/anno_train_bin/7.png\n",
      "./banana2/anno_train_bin/8.png\n",
      "./banana2/anno_train_bin/9.png\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resize Train Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\r\n",
    "# Read in folder anno_red\r\n",
    "path_anno_train = \"./banana2/image_train\"\r\n",
    "fullNameList = []\r\n",
    "nameList = []\r\n",
    "for filename in os.listdir(path_anno_train):\r\n",
    "  if filename.endswith('png'):\r\n",
    "    fullNameList.append(path_anno_train+'/'+os.path.join(filename))\r\n",
    "    nameList.append(os.path.join(filename))\r\n",
    "print(nameList)\r\n",
    "print(fullNameList)\r\n",
    "# Resize to 256x256\r\n",
    "for i,value in enumerate(fullNameList):\r\n",
    "    print(value)\r\n",
    "    src_img = cv2.imread(value)\r\n",
    "    des_img = cv2.resize(src_img, (256,256))\r\n",
    "    cv2.imwrite(\"./banana2/image_train_resized/\"+nameList[i],des_img)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.png', '10.png', '11.png', '12.png', '13.png', '14.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n",
      "['./banana2/image_train/1.png', './banana2/image_train/10.png', './banana2/image_train/11.png', './banana2/image_train/12.png', './banana2/image_train/13.png', './banana2/image_train/14.png', './banana2/image_train/2.png', './banana2/image_train/3.png', './banana2/image_train/4.png', './banana2/image_train/5.png', './banana2/image_train/6.png', './banana2/image_train/7.png', './banana2/image_train/8.png', './banana2/image_train/9.png']\n",
      "./banana2/image_train/1.png\n",
      "./banana2/image_train/10.png\n",
      "./banana2/image_train/11.png\n",
      "./banana2/image_train/12.png\n",
      "./banana2/image_train/13.png\n",
      "./banana2/image_train/14.png\n",
      "./banana2/image_train/2.png\n",
      "./banana2/image_train/3.png\n",
      "./banana2/image_train/4.png\n",
      "./banana2/image_train/5.png\n",
      "./banana2/image_train/6.png\n",
      "./banana2/image_train/7.png\n",
      "./banana2/image_train/8.png\n",
      "./banana2/image_train/9.png\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Segmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "''' \r\n",
    "#install these package\r\n",
    "pip install tensorflow==2.4.1 --user\r\n",
    "pip install keras==2.4.3 --user\r\n",
    "pip install keras-segmentation --user \r\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from tensorflow import keras \r\n",
    "from tensorflow.keras.preprocessing import image\r\n",
    "from keras_segmentation.models.unet import vgg_unet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608, \r\n",
    "                 channels=3 # Sets the number of input channels\r\n",
    "                 )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'get_file'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6780/1456374419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608, \n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;31m# Sets the number of input channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_segmentation\\models\\unet.py\u001b[0m in \u001b[0;36mvgg_unet\u001b[1;34m(n_classes, input_height, input_width, encoder_level, channels)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvgg_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m416\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m608\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     model = _unet(n_classes, get_vgg_encoder,\n\u001b[0m\u001b[0;32m    122\u001b[0m                   input_height=input_height, input_width=input_width, channels=channels)\n\u001b[0;32m    123\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"vgg_unet\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_segmentation\\models\\unet.py\u001b[0m in \u001b[0;36m_unet\u001b[1;34m(n_classes, encoder, l1_skip_conn, input_height, input_width, channels)\u001b[0m\n\u001b[0;32m     70\u001b[0m           input_width=608, channels=3):\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     img_input, levels = encoder(\n\u001b[0m\u001b[0;32m     73\u001b[0m         input_height=input_height, input_width=input_width, channels=channels)\n\u001b[0;32m     74\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_segmentation\\models\\vgg16.py\u001b[0m in \u001b[0;36mget_vgg_encoder\u001b[1;34m(input_height, input_width, pretrained, channels)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         VGG_Weights_path = keras.utils.get_file(\n\u001b[0m\u001b[0;32m     78\u001b[0m             pretrained_url.split(\"/\")[-1], pretrained_url)\n\u001b[0;32m     79\u001b[0m         \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVGG_Weights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'get_file'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# When using custom callbacks, the default checkpoint saver is removed\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "                filepath=\"model_checkpoints/\" + model.name + \".{epoch:05d}\",\n",
    "                save_weights_only=True,\n",
    "                verbose=True\n",
    "            ),\n",
    "    EarlyStopping()\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset-banana/images_prepped_train/\",\n",
    "    train_annotations = \"dataset-banana/image_train/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5, \n",
    "    read_image_type = 1  # Sets how opencv will read the images\n",
    "                       # cv2.IMREAD_COLOR = 1 (rgb),\n",
    "                       # cv2.IMREAD_GRAYSCALE = 0,\n",
    "                       # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "6b0dc0957f28c93745282d893b8763069602786a0bf1aa4d3640c9a723685fd9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}